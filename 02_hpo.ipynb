{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Training using Accelerator API\n",
    "\n",
    "In this notebook you will learn how to submit a model and dataset to the Watson Machine Learning Accelerator (WMLA) API to run Hyper Parameter Optimization (HPO).  \n",
    "\n",
    "For this notebook you will use a model and dataset that have already been setup to leverage the API.  For details on the API see this link in the Knowledge Center (KC).\n",
    "\n",
    "[API Documentation](https://www.ibm.com/support/knowledgecenter/en/SSFHA8_1.2.1/cm/deeplearning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "To use the WMLA API, we will be using the python requests library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T14:48:26.984576Z",
     "start_time": "2020-05-26T14:48:26.570702Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "import json\n",
    "import time\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "import tarfile\n",
    "import tempfile\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "# utility print function\n",
    "def nprint(mystring) :\n",
    "    print(\"**{}** : {}\".format(sys._getframe(1).f_code.co_name,mystring))\n",
    "\n",
    "# utility makedir\n",
    "def makeDirIfNotExist(directory) :\n",
    "    if not os.path.exists(directory):  \n",
    "        nprint(\"Making directory {}\".format(directory))\n",
    "        os.makedirs(directory) \n",
    "    else :\n",
    "        nprint(\"Directory {} already exists .. \".format(directory))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment details and Project Config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T14:48:28.032559Z",
     "start_time": "2020-05-26T14:48:28.025146Z"
    }
   },
   "outputs": [],
   "source": [
    "def getconfig(cfg_in={}):\n",
    "    cfg = {}\n",
    "    cfg[\"master_host\"] = 'https://p10a117.pbm.ihost.com'\n",
    "    cfg[\"dli_rest_port\"] = '9243'\n",
    "    cfg[\"sc_rest_port\"] = '8643'\n",
    "    cfg[\"num_images\"] = {\"train\":200,\"valid\":20,\"test\":20}\n",
    "    # ==== CLASS ENTER User login details below =====\n",
    "    cfg[\"wmla_user\"] = 'vanstee'  \n",
    "    cfg[\"wmla_pwd\"] = 'pwvanstee'\n",
    "    # ==== CLASS ENTER User login details above =====\n",
    "    cfg[\"sig_name\"]  = 'b0p036a-dliauto'\n",
    "    cfg[\"code_dir\"] = \"/gpfs/software/wmla-p10a117/dli_data_fs/models/pytorch_hpo\"\n",
    "\n",
    "    # overwrite configs if passed\n",
    "    for (k,v) in cfg_in.items() :\n",
    "        nprint(\"Overriding Config {}:{} with {}\".format(k,cfg[k],v))\n",
    "        cfg[k] = v\n",
    "    return cfg\n",
    "\n",
    "# cfg is used as a global variable throughout this notebook\n",
    "cfg=getconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T14:48:54.955253Z",
     "start_time": "2020-05-26T14:48:54.944091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC API Endpoints : https://p10a117.pbm.ihost.com:8643/platform/rest/conductor/v1\n",
      "DL API Endpoints : https://p10a117.pbm.ihost.com:9243/platform/rest/deeplearning/v1\n",
      "('vanstee', 'pwvanstee')\n",
      "/gpfs/home/s4s004/vanstee/2020-05-wmla/tmp/vanstee.modelDir.tar\n"
     ]
    }
   ],
   "source": [
    "# REST call variables\n",
    "commonHeaders = {'Accept': 'application/json'}\n",
    "\n",
    "# Use closures for cfg for now ..\n",
    "def get_tmp_dir() :\n",
    "    return \"/gpfs/home/s4s004/\"+cfg[\"wmla_user\"]+\"/2020-05-wmla/tmp\"\n",
    "\n",
    "def get_tar_file() :\n",
    "    return get_tmp_dir() + \"/\" + cfg[\"wmla_user\"]+\".modelDir.tar\"\n",
    "\n",
    "#get api endpoint\n",
    "def get_ep(mode=\"sc\") :\n",
    "    if mode==\"sc\" :\n",
    "        sc_rest_url =  cfg[\"master_host\"] +':'+ cfg[\"sc_rest_port\"] +'/platform/rest/conductor/v1'\n",
    "        return sc_rest_url\n",
    "    elif(mode==\"dl\") :\n",
    "        dl_rest_url = cfg[\"master_host\"] +':'+cfg[\"dli_rest_port\"] +'/platform/rest/deeplearning/v1'\n",
    "        return dl_rest_url\n",
    "    else :\n",
    "        nprint(\"Error mode : {} not supported\".format(mode))\n",
    "\n",
    "def myauth():\n",
    "    return(cfg[\"wmla_user\"],cfg[\"wmla_pwd\"])\n",
    "\n",
    "print (\"SC API Endpoints : {}\".format(get_ep(\"sc\")))\n",
    "print (\"DL API Endpoints : {}\".format(get_ep(\"dl\")))\n",
    "print (myauth())\n",
    "print (get_tar_file())\n",
    "#myauth = (wmla_user, wmla_pwd)\n",
    "\n",
    "# Setup Requests session\n",
    "req = requests.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is any existing hpo tasks and also verify the platform health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rest API: **GET platform/rest/deeplearning/v1/hypersearch**\n",
    "- Description: Get all the hpo task that the login user can access.\n",
    "- OUTPUT: A list of hpo tasks and each one with the same format which can be found in the api doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T14:49:11.788732Z",
     "start_time": "2020-05-26T14:49:11.616505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**hpo_health_check** : getTuneStatusUrl: https://p10a117.pbm.ihost.com:9243/platform/rest/deeplearning/v1/hypersearch\n",
      "**hpo_health_check** : Hpo task: kelvinl-hpo-254313202512616, State: FINISHED\n",
      "**hpo_health_check** : Hpo task: kelvinl-hpo-254758923243594, State: FINISHED\n",
      "**hpo_health_check** : Hpo task: kelvinl-hpo-266345130757669, State: FAILED\n",
      "**hpo_health_check** : Hpo task: kelvinl-hpo-267216444279712, State: FINISHED\n",
      "**hpo_health_check** : Hpo task: kelvinl-hpo-403697921838806, State: FAILED\n",
      "**hpo_health_check** : Hpo task: kelvinl-hpo-404372545448297, State: FAILED\n",
      "**hpo_health_check** : Hpo task: kelvinl-hpo-404624765236135, State: FAILED\n",
      "**hpo_health_check** : Hpo task: kelvinl-hpo-405300918575393, State: FAILED\n",
      "**hpo_health_check** : Hpo task: kelvinl-hpo-405544795318004, State: FINISHED\n",
      "**hpo_health_check** : Hpo task: kelvinl-hpo-406348140701279, State: FINISHED\n",
      "**hpo_health_check** : Hpo task: kelvinl-hpo-410153859499985, State: FINISHED\n",
      "**hpo_health_check** : Hpo task: vanstee-hpo-485074186466936, State: FINISHED\n",
      "**hpo_health_check** : Hpo task: vanstee-hpo-823684238385360, State: FAILED\n",
      "**hpo_health_check** : Hpo task: vanstee-hpo-825192585488444, State: FAILED\n",
      "**hpo_health_check** : Hpo task: vanstee-hpo-828636297042462, State: FAILED\n",
      "**hpo_health_check** : Hpo task: vanstee-hpo-829238047776795, State: FINISHED\n"
     ]
    }
   ],
   "source": [
    "def hpo_health_check():\n",
    "    getTuneStatusUrl = get_ep(\"dl\") + '/hypersearch'\n",
    "    nprint ('getTuneStatusUrl: %s' %getTuneStatusUrl)\n",
    "    r = req.get(getTuneStatusUrl, headers=commonHeaders, verify=False, auth=myauth())\n",
    "    \n",
    "    if not r.ok:\n",
    "        nprint('check hpo task status failed: code=%s, %s'%(r.status_code, r.content))\n",
    "    else:\n",
    "        if len(r.json()) == 0:\n",
    "            nprint('There is no hpo task been created')\n",
    "        for item in r.json():\n",
    "            nprint('Hpo task: %s, State: %s'%(item['hpoName'], item['state']))\n",
    "            #print('Best:%s'%json.dumps(item.get('best'), sort_keys=True, indent=4))\n",
    "\n",
    "hpo_health_check()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch an HPO task using API\n",
    "\n",
    "\n",
    "This part of the lab will step through the steps required to train a simple MNIST (greyscale digits) dataset using WMLA HPO through API ... \n",
    "\n",
    "We will be using the **PyTorch** deep learning framework for this example.  Lets take a look at the code .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T14:49:49.908106Z",
     "start_time": "2020-05-26T14:49:49.771112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code directory : /gpfs/software/wmla-p10a117/dli_data_fs/models/pytorch_hpo\n",
      "pytorch_mnist_HPO.py  pytorch_mnist_original.py\r\n"
     ]
    }
   ],
   "source": [
    "print(\"Code directory : {}\".format(cfg[\"code_dir\"]))\n",
    "!ls {cfg[\"code_dir\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model file update to Run HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Developer Note** \n",
    "The WMLA framework requires 2 changes to your code to support the HPO API, these are :\n",
    "- Inject hyper-parameters for the sub-training during search\n",
    "- Retrieve sub-training result metric\n",
    "\n",
    "We will cover these details in the next 2 sections\n",
    "\n",
    "For an even more detailed review, see the [documentation in Github](https://github.com/IBM/wmla-learning-path/blob/master/02_hpo_for_developers.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model update part 1 - Inject hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyper-parameters will be supplied in a file called **config.json** with JSON format,located in the current working directory and can be read direcly as the following example snippet.\n",
    "\n",
    "<pre>\n",
    "hyper_params = json.loads(open(\"<b>config.json</b>\").read())\n",
    "learning_rate = float(hyper_params.get(\"<b>learning_rate</b>\", \"0.01\"))\n",
    "</pre>\n",
    "\n",
    "After this, you can use these hyper-parameters during the model trainings. The **hyper-parameter name** and **value** type is defined through the search space part in body of REST call when launching a new hpo task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model update part 2 - Retrieve sub-training result metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of your training run, your code will need to create a file called **val_dict_list.json** with test metrics generated during training. These metrics will be used by the search algorithm to propose new sets of hyper-parameters. Please note that **val_dict_list.json** should be created under the result directory which can be retrieved through the environment variable **RESULT_DIR**.\n",
    "\n",
    "<pre>\n",
    "with open('{}/val_dict_list.json'.format(os.environ['<b>RESULT_DIR</b>']), 'w') as f:\n",
    "    json.dump(test_metrics, f)\n",
    "</pre>\n",
    "\n",
    "The content of **val_dict_list.json** will be some thing as below, **step** is some thing optional meaning the training iteration or epochs, one of **loss** and **accuracy** can be the name of target metric to optimize, at least one metric need to be included here. The specific name of metric used to optimize (minimize or maximize) is defined in the body of REST call when launching a new hpo task. \n",
    "\n",
    "```\n",
    "[\n",
    "{‘step’: 1, ‘loss’:0.2487, ‘accuracy’: 0.4523},\n",
    "{‘step’: 2, ‘loss’:0.1487, ‘accuracy’: 0.5523},\n",
    "{‘step’: 3, ‘loss’:0.1087, ‘accuracy’: 0.6523},\n",
    "…\n",
    "]\n",
    "```\n",
    "\n",
    "**We have added this to the pytorch_mnist_HPO.py file already for you!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T14:51:34.490626Z",
     "start_time": "2020-05-26T14:51:34.356901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "    # HPO - dump metric values to val_dict_list.json start\r\n",
      "    training_out =[]\r\n",
      "--\r\n",
      "            out[metric] = value\r\n",
      "        training_out.append(out)\r\n",
      "    with open('{}/val_dict_list.json'.format(os.environ['RESULT_DIR']), 'w') as f:\r\n",
      "        json.dump(training_out, f)\r\n",
      "# HPO - dump metric values to val_dict_list.json end\r\n",
      "if __name__ == '__main__':\r\n"
     ]
    }
   ],
   "source": [
    "!grep -A1 -B2 val_dict {cfg[\"code_dir\"]}/pytorch_mnist_HPO.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch HPO task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we package up our model to send to the API for HPO.  Lets see how this works ...\n",
    "\n",
    "\n",
    "\n",
    "REST API: **POST /platform/rest/deeplearning/v1/hypersearch**\n",
    "- Description: Start a new HPO task\n",
    "- Content-type: Multi-Form\n",
    "- Multi-Form Data:\n",
    "  - files: Model files tar package, ending with `.modelDir.tar`\n",
    "  - form-filed: {‘data’: ‘String format of input parameters to start hpo task, let’s call it as **hpo_input** and show its specification later’}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model file update to Run HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Package model files for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package the updated model files into a tar file ending with `.modelDir.tar`\n",
    "\n",
    "REST API expects a modelDir.tar with the model code inside ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T14:53:05.653985Z",
     "start_time": "2020-05-26T14:53:05.643151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**makeDirIfNotExist** : Directory /gpfs/home/s4s004/vanstee/2020-05-wmla/tmp already exists .. \n",
      "**make_tarfile** : Tarring up /gpfs/software/wmla-p10a117/dli_data_fs/models/pytorch_hpo to /gpfs/home/s4s004/vanstee/2020-05-wmla/tmp\n",
      "**make_tarfile** : Adding base directory to archive : pytorch_hpo\n",
      "Files : {'file': <_io.BufferedReader name='/gpfs/home/s4s004/vanstee/2020-05-wmla/tmp/vanstee.modelDir.tar'>}\n"
     ]
    }
   ],
   "source": [
    "# Tar up \n",
    "def make_tarfile():\n",
    "    makeDirIfNotExist(get_tmp_dir())\n",
    "    tar_archive_base=os.path.basename(cfg[\"code_dir\"])\n",
    "    nprint(\"Tarring up {} to {}\".format(cfg[\"code_dir\"],get_tmp_dir()))\n",
    "    nprint(\"Adding base directory to archive : {}\".format(tar_archive_base))\n",
    "    with tarfile.open(get_tar_file(), \"w:gz\") as tar:\n",
    "        tar.add(cfg[\"code_dir\"], arcname=tar_archive_base)\n",
    "#MODEL_DIR_SUFFIX = \".modelDir.tar\"\n",
    "#tempFile = tempfile.mktemp(MODEL_DIR_SUFFIX)\n",
    "\n",
    "make_tarfile()\n",
    "\n",
    "files = {'file': open(get_tar_file(), 'rb')}\n",
    "print(\"Files : {}\".format(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct POST request data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hpo_input** will be a Python dict or json format as below, convert to string when calling REST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T14:53:39.013976Z",
     "start_time": "2020-05-26T14:53:39.004734Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note, this \n",
    "data =  {\n",
    "        'modelSpec': # Define the model training related parameters\n",
    "        {\n",
    "            # Spark instance group which will be used to run the HPO sub-trainings. The Spark instance group selected\n",
    "            # here should match the sub-training args, for example, if the sub-training args try to run a EDT job,\n",
    "            # then we should put a Spark instance group with capability to run EDT job here.\n",
    "            'sigName': cfg[\"sig_name\"],\n",
    "\n",
    "            # These are the arguments we'll pass to the execution engine; they follow the same conventions\n",
    "            # of the dlicmd.py command line launcher\n",
    "            #\n",
    "            # See:\n",
    "            #   https://www.ibm.com/support/knowledgecenter/en/SSFHA8_1.2.1/cm/dlicmd.html\n",
    "            # In this example, args after --model-dir are all the required parameter for the original model itself.\n",
    "            #\n",
    "            'args': '--exec-start PyTorch --cs-datastore-meta type=fs --python-version 3.6\\\n",
    "                     --gpuPerWorker 1 --model-main pytorch_mnist_HPO.py --model-dir pytorch_hpo\\\n",
    "                     --debug-level debug'\n",
    "                \n",
    "        },\n",
    "    \n",
    "        'algoDef': # Define the parameters for search algorithms\n",
    "        {\n",
    "            # Name of the search algorithm, one of Random, Bayesian, Tpe, Hyperband, ExperimentGridSearch\n",
    "            'algorithm': 'Random', \n",
    "            # Max running time of the hpo task in minutes, -1 means unlimited\n",
    "            'maxRunTime': 60,  \n",
    "            # Max number of training job to submitted for hpo task, -1 means unlimited’,\n",
    "            'maxJobNum': 4,            \n",
    "            # Max number of training job to run in parallel, default 1. It depends on both the\n",
    "            # avaiable resource and if the search algorithm support to run in parallel, current only Random\n",
    "            # fully supports to run in parallel, Hyperband and Tpe supports to to in parellel in some phase,\n",
    "            # Bayesian runs in sequence now.\n",
    "            'maxParalleJobNum': 2, \n",
    "            # Name of the target metric that we are trying to optimize when searching hyper-parameters.\n",
    "            # It is the same metric name that the model update part 2 trying to dump.\n",
    "            'objectiveMetric' : 'loss',\n",
    "            # Strategy as how to optimize the hyper-parameters, minimize means to find better hyper-parameters to\n",
    "            # make the above objectiveMetric as small as possible, maximize means the opposite.\n",
    "            'objective' : 'minimize',\n",
    "        },\n",
    "    \n",
    "        # Define the hyper-paremeters to search and the corresponding search space.\n",
    "        'hyperParams':\n",
    "        [\n",
    "             {\n",
    "                 # Hyperparameter name, which will be the hyper-parameter key in config.json\n",
    "                 'name': 'learning_rate',\n",
    "                 # One of Range, Discrete\n",
    "                 'type': 'Range',\n",
    "                 # one of int, double, str\n",
    "                 'dataType': 'DOUBLE',\n",
    "                 # lower bound and upper bound when type=range and dataType=double\n",
    "                 'minDbVal': 0.001,\n",
    "                 'maxDbVal': 0.1,\n",
    "                 # lower bound and upper bound when type=range and dataType=int\n",
    "                 'minIntVal': 0,\n",
    "                 'maxIntVal': 0,\n",
    "                 # Discrete value list when type=discrete\n",
    "                 'discreteDbVal': [],\n",
    "                 'discreteIntVal': [],\n",
    "                 'discreateStrVal': []\n",
    "                 #step size to split the Range space. ONLY valid when type is Range\n",
    "                 #'step': '0.002',\n",
    "             }\n",
    "         ]\n",
    "    }\n",
    "mydata={'data':json.dumps(data)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the Post request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit hpo task through the Post call and a hpo name/id as string format will get back.\n",
    "\n",
    "**Note**:This cannot be submitted twice.. you need to rebuild the tar file prior to resubmitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T14:53:43.164698Z",
     "start_time": "2020-05-26T14:53:43.010679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**submit_job** : startTuneUrl : https://p10a117.pbm.ihost.com:9243/platform/rest/deeplearning/v1/hypersearch\n",
      "**submit_job** : files : {'file': <_io.BufferedReader name='/gpfs/home/s4s004/vanstee/2020-05-wmla/tmp/vanstee.modelDir.tar'>}\n",
      "**submit_job** : myauth() : ('vanstee', 'pwvanstee')\n",
      "\n",
      "Model submitted successfully: vanstee-hpo-831009472195092\n",
      "hpo_job_id : vanstee-hpo-831009472195092\n"
     ]
    }
   ],
   "source": [
    "def submit_job():\n",
    "    startTuneUrl=get_ep('dl') + '/hypersearch'\n",
    "    nprint(\"startTuneUrl : {}\".format(startTuneUrl))\n",
    "    nprint(\"files : {}\".format(files))\n",
    "    nprint(\"myauth() : {}\".format(myauth()))\n",
    "    #print(\"hpo_job_id : {}\".format(hpo_job_id))\n",
    "    r = req.post(startTuneUrl, headers=commonHeaders, data=mydata, files=files, verify=False, auth=myauth())\n",
    "    hpo_name=None\n",
    "    if r.ok:\n",
    "        hpo_name = r.json()\n",
    "        print ('\\nModel submitted successfully: {}'.format(hpo_name))\n",
    "        \n",
    "    else:\n",
    "        print('\\nModel submission failed with code={}, {}'. format(r.status_code, r.content))\n",
    "    return hpo_name\n",
    "\n",
    "hpo_job_id = submit_job()\n",
    "print(\"hpo_job_id : {}\".format(hpo_job_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T15:04:36.814227Z",
     "start_time": "2020-05-26T14:53:50.831240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refreshing every 10 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hyperParams</th>\n",
       "      <th>state</th>\n",
       "      <th>metricVal</th>\n",
       "      <th>maxiteration</th>\n",
       "      <th>appId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'name': 'learning_rate', 'dataType': 'double', 'userDefined': False, 'fixedVal': '0.07176378069813329'}]</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.045087</td>\n",
       "      <td>0</td>\n",
       "      <td>vanstee-831011048458738-1807318326</td>\n",
       "      <td>driver-20200526105345-0106-1c900f6f-d4eb-4d86-885e-caaf54b2cba3</td>\n",
       "      <td>2020-05-26 10:53:45</td>\n",
       "      <td>2020-05-26 10:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'name': 'learning_rate', 'dataType': 'double', 'userDefined': False, 'fixedVal': '0.07950452443574245'}]</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.043343</td>\n",
       "      <td>0</td>\n",
       "      <td>vanstee-831016981293908-1256126962</td>\n",
       "      <td>driver-20200526105351-0107-6fb2c545-0336-473c-998f-c5a644468c7d</td>\n",
       "      <td>2020-05-26 10:53:51</td>\n",
       "      <td>2020-05-26 10:59:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'name': 'learning_rate', 'dataType': 'double', 'userDefined': False, 'fixedVal': '0.08983621328711912'}]</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.041888</td>\n",
       "      <td>0</td>\n",
       "      <td>vanstee-831328606570062-1802464889</td>\n",
       "      <td>driver-20200526105902-0108-984f08db-9681-4ca2-8b0b-df4e1a93e4bf</td>\n",
       "      <td>2020-05-26 10:59:03</td>\n",
       "      <td>2020-05-26 11:04:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'name': 'learning_rate', 'dataType': 'double', 'userDefined': False, 'fixedVal': '0.0693363050432297'}]</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.045947</td>\n",
       "      <td>0</td>\n",
       "      <td>vanstee-831334628394027-477840709</td>\n",
       "      <td>driver-20200526105908-0109-b5e0bc6f-5be8-4cf9-91da-db9d16f6bdf4</td>\n",
       "      <td>2020-05-26 10:59:08</td>\n",
       "      <td>2020-05-26 11:04:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "\n",
       "                                                                                                  hyperParams  \\\n",
       "0  [{'name': 'learning_rate', 'dataType': 'double', 'userDefined': False, 'fixedVal': '0.07176378069813329'}]   \n",
       "1  [{'name': 'learning_rate', 'dataType': 'double', 'userDefined': False, 'fixedVal': '0.07950452443574245'}]   \n",
       "2  [{'name': 'learning_rate', 'dataType': 'double', 'userDefined': False, 'fixedVal': '0.08983621328711912'}]   \n",
       "3   [{'name': 'learning_rate', 'dataType': 'double', 'userDefined': False, 'fixedVal': '0.0693363050432297'}]   \n",
       "\n",
       "      state  metricVal  maxiteration                               appId  \\\n",
       "0  FINISHED   0.045087             0  vanstee-831011048458738-1807318326   \n",
       "1  FINISHED   0.043343             0  vanstee-831016981293908-1256126962   \n",
       "2  FINISHED   0.041888             0  vanstee-831328606570062-1802464889   \n",
       "3  FINISHED   0.045947             0   vanstee-831334628394027-477840709   \n",
       "\n",
       "                                                          driverId  \\\n",
       "0  driver-20200526105345-0106-1c900f6f-d4eb-4d86-885e-caaf54b2cba3   \n",
       "1  driver-20200526105351-0107-6fb2c545-0336-473c-998f-c5a644468c7d   \n",
       "2  driver-20200526105902-0108-984f08db-9681-4ca2-8b0b-df4e1a93e4bf   \n",
       "3  driver-20200526105908-0109-b5e0bc6f-5be8-4cf9-91da-db9d16f6bdf4   \n",
       "\n",
       "             startTime              endTime  \n",
       "0  2020-05-26 10:53:45  2020-05-26 10:58:00  \n",
       "1  2020-05-26 10:53:51  2020-05-26 10:59:01  \n",
       "2  2020-05-26 10:59:03  2020-05-26 11:04:19  \n",
       "3  2020-05-26 10:59:08  2020-05-26 11:04:19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'best': { 'appId': 'vanstee-831328606570062-1802464889',\n",
      "            'driverId': 'driver-20200526105902-0108-984f08db-9681-4ca2-8b0b-df4e1a93e4bf',\n",
      "            'endTime': '2020-05-26 11:04:19',\n",
      "            'hyperParams': [ { 'dataType': 'double',\n",
      "                               'fixedVal': '0.08983621328711912',\n",
      "                               'name': 'learning_rate',\n",
      "                               'userDefined': False}],\n",
      "            'id': 2,\n",
      "            'maxiteration': 0,\n",
      "            'metricVal': 0.04188754959106445,\n",
      "            'startTime': '2020-05-26 10:59:03',\n",
      "            'state': 'FINISHED'},\n",
      "  'complete': 4,\n",
      "  'createtime': '2020-05-26 10:53:43',\n",
      "  'creator': 'vanstee',\n",
      "  'duration': '00:10:36',\n",
      "  'experiments': [ { 'appId': 'vanstee-831011048458738-1807318326',\n",
      "                     'driverId': 'driver-20200526105345-0106-1c900f6f-d4eb-4d86-885e-caaf54b2cba3',\n",
      "                     'endTime': '2020-05-26 10:58:00',\n",
      "                     'hyperParams': [ { 'dataType': 'double',\n",
      "                                        'fixedVal': '0.07176378069813329',\n",
      "                                        'name': 'learning_rate',\n",
      "                                        'userDefined': False}],\n",
      "                     'id': 0,\n",
      "                     'maxiteration': 0,\n",
      "                     'metricVal': 0.04508685417175293,\n",
      "                     'startTime': '2020-05-26 10:53:45',\n",
      "                     'state': 'FINISHED'},\n",
      "                   { 'appId': 'vanstee-831016981293908-1256126962',\n",
      "                     'driverId': 'driver-20200526105351-0107-6fb2c545-0336-473c-998f-c5a644468c7d',\n",
      "                     'endTime': '2020-05-26 10:59:01',\n",
      "                     'hyperParams': [ { 'dataType': 'double',\n",
      "                                        'fixedVal': '0.07950452443574245',\n",
      "                                        'name': 'learning_rate',\n",
      "                                        'userDefined': False}],\n",
      "                     'id': 1,\n",
      "                     'maxiteration': 0,\n",
      "                     'metricVal': 0.04334258308410645,\n",
      "                     'startTime': '2020-05-26 10:53:51',\n",
      "                     'state': 'FINISHED'},\n",
      "                   { 'appId': 'vanstee-831328606570062-1802464889',\n",
      "                     'driverId': 'driver-20200526105902-0108-984f08db-9681-4ca2-8b0b-df4e1a93e4bf',\n",
      "                     'endTime': '2020-05-26 11:04:19',\n",
      "                     'hyperParams': [ { 'dataType': 'double',\n",
      "                                        'fixedVal': '0.08983621328711912',\n",
      "                                        'name': 'learning_rate',\n",
      "                                        'userDefined': False}],\n",
      "                     'id': 2,\n",
      "                     'maxiteration': 0,\n",
      "                     'metricVal': 0.04188754959106445,\n",
      "                     'startTime': '2020-05-26 10:59:03',\n",
      "                     'state': 'FINISHED'},\n",
      "                   { 'appId': 'vanstee-831334628394027-477840709',\n",
      "                     'driverId': 'driver-20200526105908-0109-b5e0bc6f-5be8-4cf9-91da-db9d16f6bdf4',\n",
      "                     'endTime': '2020-05-26 11:04:19',\n",
      "                     'hyperParams': [ { 'dataType': 'double',\n",
      "                                        'fixedVal': '0.0693363050432297',\n",
      "                                        'name': 'learning_rate',\n",
      "                                        'userDefined': False}],\n",
      "                     'id': 3,\n",
      "                     'maxiteration': 0,\n",
      "                     'metricVal': 0.04594717788696289,\n",
      "                     'startTime': '2020-05-26 10:59:08',\n",
      "                     'state': 'FINISHED'}],\n",
      "  'failed': 0,\n",
      "  'hpoName': 'vanstee-hpo-831009472195092',\n",
      "  'progress': '4/4',\n",
      "  'running': 0,\n",
      "  'state': 'FINISHED'}\n"
     ]
    }
   ],
   "source": [
    "getHpoUrl = get_ep('dl') +'/hypersearch/'+ hpo_job_id\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "keep_running=True\n",
    "rr=10\n",
    "while(keep_running):\n",
    "    res = req.get(getHpoUrl, headers=commonHeaders, verify=False, auth=myauth())\n",
    "    experiments=res.json()['experiments']\n",
    "    experiments = pd.DataFrame.from_dict(experiments)\n",
    "    pd.set_option('max_colwidth', 120)\n",
    "    clear_output()\n",
    "    print(\"Refreshing every {} seconds\".format(rr))\n",
    "    display(experiments)\n",
    "    pp.pprint(res.json())\n",
    "    if(res.json()['state'] not in ['SUBMITTED','RUNNING']) :\n",
    "        keep_running=False\n",
    "    time.sleep(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T12:53:37.740297Z",
     "start_time": "2020-05-26T12:53:37.667436Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if not res.ok:\n",
    "    print('get hpo task failed: code=%s, %s'%(res.status_code, res.content))\n",
    "else:\n",
    "    json_out=res.json()\n",
    "    \n",
    "    while json_out['state'] in ['SUBMITTED','RUNNING']:\n",
    "        clear_output()\n",
    "        print('Hpo task %s state %s progress %s%%'%(hpo_job_id, json_out['state'], json_out['progress']))\n",
    "        time.sleep(10)\n",
    "        res = req.get(getHpoUrl, headers=commonHeaders, verify=False, auth=myauth())\n",
    "        json_out=res.json()\n",
    "        \n",
    "        experiments_length = len(json_out['experiments'])\n",
    "       \n",
    "        ####\n",
    "        ## Query the list of 6 sub-training of current batch, as maxParalleJobNum=6\n",
    "        ###      \n",
    "        count=0\n",
    "        Experiment = []\n",
    "        while (count < experiments_length):\n",
    "                appID = json_out['experiments'][count]['appId']\n",
    "                print ('appID: %s,' %appID )\n",
    "                print ('count: %d' %count)\n",
    "                Experiment.insert(count, appID)\n",
    "                count+=1\n",
    " \n",
    "        ####\n",
    "        ## Query the state of 6 sub-training of current batch\n",
    "        ###\n",
    "    \n",
    "        count = 0\n",
    "        while (count < len(Experiment)):\n",
    "                r = requests.get(get_ep('dl')+'/execs/'+Experiment[count], auth=myauth(), headers=commonHeaders, verify=False).json()    \n",
    "                if not res.ok:\n",
    "                    print('get hpo task failed: code=%s, %s'%(res.status_code, res.content))\n",
    "                else:\n",
    "                    print ('Experiement %s state: %s' %(Experiment[count], r['state']))\n",
    "                count+=1\n",
    "        \n",
    "        #time.sleep(30)\n",
    "        #print ('state:' + json_out['state'] )\n",
    "\n",
    "        \n",
    "print('Hpo task %s completes with state %s'%(hpo_job_id, json_out['state']))\n",
    "print(json.dumps(json_out, indent=4, sort_keys=True))\n",
    " \n",
    "mya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
